{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Employees Attrition\n",
    "\n",
    "In this activity, you will apply your knowledge of deep learning models to predict whether an employee is likely to depart from a company.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "The steps for this activity are broken out into the following sections:\n",
    "\n",
    "* Preprocess the data.\n",
    "\n",
    "* Create a neural network model to predict employee attrition.\n",
    "\n",
    "* Train and evaluate the neural network model.\n",
    "\n",
    "\n",
    "#### Preprocess the Data \n",
    "\n",
    "1. Read the `HR-Employee-Attrition.csv` file from the Resources folder and create a DataFrame.\n",
    "\n",
    "2. Review the resulting DataFrame. Check the data type associated with each column to identify categorical and non-categorical variables.\n",
    "\n",
    "> **Hint** Recall that categorical variables have an `object` data type.\n",
    "\n",
    "3. Create a list of categorical variables.\n",
    "\n",
    "> **Rewind** The Pandas DataFrame `dtypes` property returns a Pandas Series that displays the data type of each column. The column name is the index. You can create the list of categorical variables manually. Or, you can use Pandas filtering. For more detail about the filtering process, review the [`dtypes` documentation at Pandas API reference](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html).\n",
    "\n",
    "4. Use the `OneHotEncoder` module from scikit-learn to encode the data set's categorical variables.\n",
    "\n",
    "5. Create a new DataFrame named `attrition_df` that contains the encoded categorical variables and the numerical variables from the original dataset.\n",
    "\n",
    "> **Note** To complete this step, you will employ the Pandas `concat()` function, which was introduced earlier in the course. Recall that we use the `concat` function to combine data from different DataFrames into a new DataFrame. In this case, you’ll use `concat` to create a new DataFrame containing the preprocessed data. You can learn more about the `concat` function in [this section of the Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html).\n",
    "\n",
    "6. Use `attrition_df` to create the features (`X`) and target (`y`) sets. \n",
    "\n",
    "    * In this activity, we want to build a model that predicts whether a person is at risk for attrition. So, we must separate the attrition columns from the rest of the input data. In fact, because the attrition data is binary (one of two values), we only need to keep the “Attrition_Yes” column. We can ignore the “Attrition_No” column, because it is redundant. So, the “Attrition_Yes” column will become the target set `y`.\n",
    "\n",
    "    * The rest of the DataFrame columns will become the features set `X`. \n",
    "    \n",
    "7. Create the training and testing sets using the `train_test_split` function from scikit-learn.\n",
    "\n",
    "8. Use scikit-learn’s `StandardScaler` to standardize the numerical features.\n",
    "\n",
    "#### Create a Neural Network Model to Predict Employee Attrition\n",
    "\n",
    "1. Use the optimization techniques presented in this lesson to create a deep neural network model with two hidden layers.\n",
    "\n",
    "    * Set a variable `number_input_features` equal to the number of input features.\n",
    "\n",
    "    * Set a variable `hidden_nodes_layer1` equal to an integer number close to the mean of the number of input features and the number of neurons in the output layer.\n",
    "\n",
    "    * Set a variable `hidden_nodes_layer2` equal to an integer number close to the mean of the number of hidden nodes defined for the first layer and the number of neurons in the output layer.\n",
    "\n",
    "    * Add the model’s layers, and use the `relu` activation function for each hidden layer.\n",
    "\n",
    "    * This model will predict a binary output. So, add an output layer with one neuron, and use the `sigmoid` activation function.\n",
    "\n",
    "> **Hint** To set the number of input features, you can fetch the length of the first element, like this: `number_input_features = len(X_train.iloc[0])`.\n",
    "\n",
    "2. Display the structure of your model using the `summary` function.\n",
    "\n",
    "3. Compile the model. Use the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` metric.\n",
    "\n",
    "\n",
    "#### Train and Evaluate the Neural Network Model\n",
    "\n",
    "1. Train (fit) the neural network model. Use the training data and set 100 epochs.\n",
    "\n",
    "2. Evaluate the model using the test data to determine its loss and accuracy.\n",
    "\n",
    "3. Save and export your model to an HDF5 file. Name the file `employee_attrition.h5`.\n",
    "\n",
    "## References:\n",
    "\n",
    "[Keras Sequential model](https://keras.io/api/models/sequential/)\n",
    "\n",
    "[Keras Dense module](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "[Keras evaluate](https://keras.io/api/models/model_training_apis/)\n",
    "\n",
    "[SKLearn OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `HR-Employee-Attrition.csv` file from the Resources folder and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HR-Employee-Attrition.csv file from the Resources folder into a Pandas DataFrame\n",
    "employee_df = pd.read_csv(\n",
    "    Path(\"../Resources/HR-Employee-Attrition.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Review the resulting DataFrame. Check the data type associated with each column to identify categorical and non-categorical variables.\n",
    "\n",
    "> **Hint** Recall that categorical variables have an `object` data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the DataFrame\n",
    "employee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                          int64\n",
       "Attrition                   object\n",
       "BusinessTravel              object\n",
       "DailyRate                    int64\n",
       "Department                  object\n",
       "DistanceFromHome             int64\n",
       "Education                    int64\n",
       "EducationField              object\n",
       "EmployeeCount                int64\n",
       "EmployeeNumber               int64\n",
       "EnvironmentSatisfaction      int64\n",
       "Gender                      object\n",
       "HourlyRate                   int64\n",
       "JobInvolvement               int64\n",
       "JobLevel                     int64\n",
       "JobRole                     object\n",
       "JobSatisfaction              int64\n",
       "MaritalStatus               object\n",
       "MonthlyIncome                int64\n",
       "MonthlyRate                  int64\n",
       "NumCompaniesWorked           int64\n",
       "Over18                      object\n",
       "OverTime                    object\n",
       "PercentSalaryHike            int64\n",
       "PerformanceRating            int64\n",
       "RelationshipSatisfaction     int64\n",
       "StandardHours                int64\n",
       "StockOptionLevel             int64\n",
       "TotalWorkingYears            int64\n",
       "TrainingTimesLastYear        int64\n",
       "WorkLifeBalance              int64\n",
       "YearsAtCompany               int64\n",
       "YearsInCurrentRole           int64\n",
       "YearsSinceLastPromotion      int64\n",
       "YearsWithCurrManager         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the data types associated with the columns\n",
    "employee_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a list of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attrition',\n",
       " 'BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'Over18',\n",
       " 'OverTime']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = list(employee_df.dtypes[employee_df.dtypes == \"object\"].index)\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the `OneHotEncoder` module from scikit-learn to encode the data set's categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhillman\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Encode categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(employee_df[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the encoded variables\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# The column names should match those of the encoded variables\u001b[39;00m\n\u001b[0;32m      3\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m      4\u001b[0m     encoded_data,\n\u001b[1;32m----> 5\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m(categorical_variables)\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m encoded_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "# The column names should match those of the encoded variables\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns = enc.get_feature_names(categorical_variables)\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create a new DataFrame named `attrition_df` that contains the encoded categorical variables and the numerical variables from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the columnns containing numerical variables from the original dataset\n",
    "numerical_variables_df = employee_df.drop(columns = categorical_variables)\n",
    "\n",
    "# Review the DataFrame\n",
    "numerical_variables_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Pandas concat function, combine the DataFrames the contain the encoded categorical data and the numerical data\n",
    "attition_df = pd.concat(\n",
    "    [\n",
    "        numerical_variables_df,\n",
    "        encoded_df\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Reveiw the DataFrame\n",
    "attition_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Use `attrition_df` to create the features (`X`) and target (`y`) sets. \n",
    "\n",
    "    * In this activity, we want to build a model that predicts whether a person is at risk for attrition. So, we must separate the attrition columns from the rest of the input data. In fact, because the attrition data is binary (one of two values), we only need to keep the “Attrition_Yes” column. We can ignore the “Attrition_No” column, because it is redundant. So, the “Attrition_Yes” column will become the target set `y`.\n",
    "\n",
    "    * The rest of the DataFrame columns will become the features set `X`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target set y using the Attrition_Yes column\n",
    "y = attition_df[\"Attrition_Yes\"]\n",
    "\n",
    "# Display a sample of y\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set X by selecting all columns but Attrition_Yes and Attrition_No\n",
    "X = attition_df.drop(columns=[\"Attrition_Yes\", \"Attrition_No\"])\n",
    "\n",
    "# Review the features DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create the training and testing sets using the `train_test_split` function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Use scikit-learn’s `StandardScaler` to standardize the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create a Neural Network Model to Predict Employee Attrition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the optimization techniques presented in this lesson to create a deep neural network model with two hidden layers.\n",
    "\n",
    "    * Set a variable `number_input_features` equal to the number of input features.\n",
    "\n",
    "    * Set a variable `hidden_nodes_layer1` equal to an integer number close to the mean of the number of input features and the number of neurons in the output layer.\n",
    "\n",
    "    * Set a variable `hidden_nodes_layer2` equal to an integer number close to the mean of the number of hidden nodes defined for the first layer and the number of neurons in the output layer.\n",
    "\n",
    "    * Add the model’s layers, and use the `relu` activation function for each hidden layer.\n",
    "\n",
    "    * This model will predict a binary output. So, add an output layer with one neuron, and use the `sigmoid` activation function.\n",
    "\n",
    "> **Hint** To set the number of input features, you can fetch the length of the first element, like this: `number_input_features = len(X_train.iloc[0])`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer\n",
    "# Use the mean of the number of input features plus the number of output nurons\n",
    "# Use the Python floor division (//) to return the quotent\n",
    "hidden_nodes_layer1 =  (number_input_features + 1) // 2 \n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer\n",
    "# Use the mean of the number of hidden nodes in the first hidden layer plus the number of output nurons\n",
    "# Use the Python floor division (//) to return the quotent\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) // 2\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first hidden layer specifying the number of inputs, the number of hidden nodes, and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Add the second hidden layer specifying the number of hidden nodes and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Display the structure of your model using the `summary` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compile the model. Use the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train and Evaluate the Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train (fit) the neural network model. Use the training data and set 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using 100 epochs and the training data\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluate the model using the test data to determine its loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Save and export your model to an HDF5 file. Name the file `employee_attrition.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's file path\n",
    "file_path = Path(\"../Resources/employee_attrition.h5\")\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
